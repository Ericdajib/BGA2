{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uebung 3 Merkmalsextraktion, binaere Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**German Traffic Sign Recognition Benchmark**\n",
    "\n",
    "Detallierte Beschreibung des Datensatzes siehe unter folgendem [Link](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset#Annotationformat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import learning_curve, train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, widgets\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globale Variablen\n",
    "Um hartcodierte Bezeichner/Namen in den Funktionen zu vermeiden, definiere an dieser Stelle alle Variablen, die global verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prohibitory Class IDs \n",
    "PROHIBITORY_CLASS_IDs = [ 0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 15, 16]\n",
    "\n",
    "# Mandatory Class IDs\n",
    "MANDATORY_CLASS_IDs = [ 33, 34, 35, 36, 37, 38, 39, 40 ]\n",
    "\n",
    "# Danger Class IDs\n",
    "DANGER_CLASS_IDs = [ 11, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 36]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Festlegen, welche Klassen betrachtet werden\n",
    "\n",
    "CONSIDERED_CLASS_IDs = [PROHIBITORY_CLASS_IDs[9], MANDATORY_CLASS_IDs[3]]\n",
    "print(CONSIDERED_CLASS_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Pfade entsprechend eurer Datenstruktu anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere den Pfad zum GTSDB-Datenordner (Detektionsdatensatz)\n",
    "PATH_TO_GTSDB_DATA_FOLDER = './dataset/FullIJCNN2013'\n",
    "# Prüfe, ob der Pfad existiert / korrekt eingegeben wurde\n",
    "assert os.path.exists(PATH_TO_GTSDB_DATA_FOLDER), \"Der angegebene Pfad existriert nicht.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere den Pfad zum GTSRB-Datenordner mit den den ppm-Dateien\n",
    "DATA_PATH_FINAL_TRAINING_IMAGES = './dataset/GTSRB/Final_Training/Images'\n",
    "\n",
    "# Prüfe, ob der Pfad existiert / korrekt eingegeben wurde\n",
    "assert os.path.exists(DATA_PATH_FINAL_TRAINING_IMAGES), \"Der angegebene Pfad existriert nicht.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere den Pfad zum GTSRB-Datenordner mit HOG Features\n",
    "DATA_PATH_HOG_01 = './dataset/GTSRB/Final_Training/HOG/HOG_01'\n",
    "\n",
    "# Prüfe, ob der Pfad existiert / korrekt eingegeben wurde\n",
    "assert os.path.exists(DATA_PATH_HOG_01), \"Der angegebene Pfad existriert nicht.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung der Klassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wiederverwendung des Codes aus UE 1\n",
    "def one_image_per_class(path_to_data_folder):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gibt ein Bild pro Klasse aus (erste Variante)\n",
    "    Argumente: Pfad zum Datenordner\n",
    "    NOTE: 从data folder中提取所有的sub folder，从每一个subfolder中提取第二章图片，并把图片的路径保存到img paths.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definiere eine leere Liste für Bildpfade\n",
    "    img_paths = []\n",
    "    \n",
    "    # Generiere eine Liste mit den Namen von Unterordnern\n",
    "    subfolders_paths = [os.path.join(path_to_data_folder, subfolder_name) \n",
    "                        for subfolder_name in os.listdir(path_to_data_folder)\n",
    "                        if os.path.isdir(os.path.join(path_to_data_folder, subfolder_name))]\n",
    "    for path in subfolders_paths:\n",
    "        assert os.path.exists(path), \"Der angegebene Pfad existriert nicht.\"\n",
    "        # Gebe z.B. das erste Bild aus\n",
    "        img_path = os.path.join(path, '00001.ppm')\n",
    "        assert os.path.exists(img_path), \"Der angegebene Pfad existriert nicht.\"\n",
    "        img_paths.append(img_path)\n",
    "        \n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img_tr_sign(idx):\n",
    "    print('ClassID {}'.format(idx))\n",
    "    plt.figure(figsize=(6,6))\n",
    "    img = plt.imread(img_paths_43[idx])\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths_43 = one_image_per_class(PATH_TO_GTSDB_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255e3b0f6d2f449bb073e6f2fa8bc477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx', max=42), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(show_img_tr_sign, idx=widgets.IntSlider(min=0,max=len(img_paths_43)-1,step=1, value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der Daten und Bilden der train- und test-Datensaetze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_datasets(CONSIDERED_CLASS_IDs, path_to_data_folder, suffix='txt'):\n",
    "    '''\n",
    "    Liest die Daten aus dem vorgegebenen Datenordner ein und teilt sie in train- und test-Datensaetze auf\n",
    "    从给定的数据文件夹中读取数据，并将其分割成训练和测试数据集。\n",
    "    '''\n",
    "    if suffix != 'txt' and suffix != 'ppm':\n",
    "        print (\"Abbruch der Funktion: Suffix nicht zutreffend. gueltige Suffixes sind txt oder ppm\")\n",
    "        return \n",
    "    \n",
    "    data = []\n",
    "    ppm_data = []\n",
    "    data_labels = []\n",
    "    subfolders_list = os.listdir(path_to_data_folder)\n",
    "    considered_subfolders = [subfolder for subfolder in subfolders_list if int(subfolder) in CONSIDERED_CLASS_IDs]\n",
    "    for subfolder in considered_subfolders:\n",
    "        path_to_considered_datafolder = os.path.join(path_to_data_folder, subfolder)\n",
    "        for filepath in os.listdir(path_to_considered_datafolder):\n",
    "            # Final Training HOG Features of GTSRB-Images\n",
    "            if filepath.endswith(suffix):\n",
    "                full_filepath = os.path.join(path_to_data_folder, subfolder, filepath)\n",
    "                assert os.path.exists(full_filepath), \"Der angegebene Pfad existriert nicht.\"\n",
    "                if suffix == 'txt':\n",
    "                    text_file = open(full_filepath, \"r\")\n",
    "                    txt_lines = text_file.read().split('\\n')\n",
    "                    txt_lines = [float(x) for x in txt_lines]\n",
    "                    data.append(txt_lines)\n",
    "                    data_labels.append(int(subfolder))\n",
    "                else:\n",
    "                    ppm_file = io.imread(full_filepath)\n",
    "                    ppm_file_resized = resize(ppm_file, (40, 40), anti_aliasing=True)\n",
    "                    data.append(ppm_file_resized)\n",
    "                    data_labels.append(int(subfolder))\n",
    "\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    data_labels = np.array(data_labels)\n",
    "    \n",
    "    X_train, X_test, y_tain, y_test = train_test_split(data,data_labels, test_size=0.25, random_state=42)\n",
    "        \n",
    "    \n",
    "    return X_train, X_test, y_tain, y_test, data, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der txt-Dateien aus dem GTSRB-Final-Training-HOG1-Datenordner\n",
    "X_train_hog_01, X_test_hog_01, y_train_hog_01, y_test_hog_01, txt_data_hog_01, data_labels_hog_01 = build_train_test_datasets(CONSIDERED_CLASS_IDs, DATA_PATH_HOG_01, suffix='txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der ppm-Dateien aus dem GTSRB-Final-Training-Images-Datenordner\n",
    "X_train_img, X_test_img, y_train_img, y_test_img, img_data, img_data_labels = build_train_test_datasets(CONSIDERED_CLASS_IDs, DATA_PATH_FINAL_TRAINING_IMAGES, suffix='ppm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(txt_data_hog_01.shape)\n",
    "print(data_labels_hog_01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of \\nX_train_img: {} \\nX_test_img: {} \\ny_train_img: {} \\ny_test_img: {}'.format(X_train_img.shape, X_test_img.shape, y_train_img.shape, y_test_img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img.shape\n",
    "io.imshow(X_train_img[9])\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merkmalsextraktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = cv2.HOGDescriptor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = cv2.HOGDescriptor()\n",
    "print('Standardeinstellung von cv2.HOGDescriptor():\\n')\n",
    "print('winSize:         {}'.format(hog.winSize))\n",
    "print('blockSize:       {}'.format(hog.blockSize))\n",
    "print('blockStride:     {}'.format(hog.blockStride))\n",
    "print('cellSize:        {}'.format(hog.cellSize))\n",
    "print('nbins:           {}'.format(hog.nbins))\n",
    "print('winSigma:        {}'.format(hog.winSigma))\n",
    "print('L2HysThreshold:  {}'.format(hog.L2HysThreshold))\n",
    "print('gammaCorrection: {}'.format(hog.gammaCorrection))\n",
    "print('nlevels:         {}'.format(hog.nlevels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_hog_params():\n",
    "    '''\n",
    "    Ueberschreibt Standardeinstellungsparameter von HOGDescriptor()\n",
    "    TODO: Waehle sinnvolle Paameter fuer deinen eigenen HOG-Deskriptor und \n",
    "    extrahiere die HOG-Features für 2 beliebige Klassen\n",
    "    '''\n",
    "    # Waehle win_size-Parameter (als Tuple anzugeben)\n",
    "    win_size = (x, y)\n",
    "    # Waehle block_size-Parameter (als Tuple anzugeben)\n",
    "    block_size = (x, y)\n",
    "    # Waehle block_stride-Parameter (als Tuple anzugeben)\n",
    "    block_stride = (x, y)\n",
    "    # Waehle cell_size-Parameter (als Tuple anzugeben)\n",
    "    cell_size = (x, y)\n",
    "    # Waehle nbins-Parameter (als Integer anzugeben)\n",
    "    nbins = x\n",
    "    hog_set = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    return hog_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on xfeatures2d_SIFT object:\n",
      "\n",
      "class xfeatures2d_SIFT(Feature2D)\n",
      " |  Method resolution order:\n",
      " |      xfeatures2d_SIFT\n",
      " |      Feature2D\n",
      " |      Algorithm\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  create(...) from builtins.type\n",
      " |      create([, nfeatures[, nOctaveLayers[, contrastThreshold[, edgeThreshold[, sigma]]]]]) -> retval\n",
      " |      .   @param nfeatures The number of best features to retain. The features are ranked by their scores\n",
      " |      .   (measured in SIFT algorithm as the local contrast)\n",
      " |      .   \n",
      " |      .   @param nOctaveLayers The number of layers in each octave. 3 is the value used in D. Lowe paper. The\n",
      " |      .   number of octaves is computed automatically from the image resolution.\n",
      " |      .   \n",
      " |      .   @param contrastThreshold The contrast threshold used to filter out weak features in semi-uniform\n",
      " |      .   (low-contrast) regions. The larger the threshold, the less features are produced by the detector.\n",
      " |      .   \n",
      " |      .   @param edgeThreshold The threshold used to filter out edge-like features. Note that the its meaning\n",
      " |      .   is different from the contrastThreshold, i.e. the larger the edgeThreshold, the less features are\n",
      " |      .   filtered out (more features are retained).\n",
      " |      .   \n",
      " |      .   @param sigma The sigma of the Gaussian applied to the input image at the octave \\#0. If your image\n",
      " |      .   is captured with a weak camera with soft lenses, you might want to reduce the number.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Feature2D:\n",
      " |  \n",
      " |  compute(...)\n",
      " |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      " |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      " |      .   (second variant).\n",
      " |      .   \n",
      " |      .   @param image Image.\n",
      " |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      " |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      " |      .   with several dominant orientations (for each orientation).\n",
      " |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      " |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      " |      .   descriptor for keypoint j-th keypoint.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      " |      .   @overload\n",
      " |      .   \n",
      " |      .   @param images Image set.\n",
      " |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      " |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      " |      .   with several dominant orientations (for each orientation).\n",
      " |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      " |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      " |      .   descriptor for keypoint j-th keypoint.\n",
      " |  \n",
      " |  defaultNorm(...)\n",
      " |      defaultNorm() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  descriptorSize(...)\n",
      " |      descriptorSize() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  descriptorType(...)\n",
      " |      descriptorType() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  detect(...)\n",
      " |      detect(image[, mask]) -> keypoints\n",
      " |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      " |      .   \n",
      " |      .   @param image Image.\n",
      " |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      " |      .   of keypoints detected in images[i] .\n",
      " |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      " |      .   matrix with non-zero values in the region of interest.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      detect(images[, masks]) -> keypoints\n",
      " |      .   @overload\n",
      " |      .   @param images Image set.\n",
      " |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      " |      .   of keypoints detected in images[i] .\n",
      " |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      " |      .   masks[i] is a mask for images[i].\n",
      " |  \n",
      " |  detectAndCompute(...)\n",
      " |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      " |      .   Detects keypoints and computes the descriptors\n",
      " |  \n",
      " |  empty(...)\n",
      " |      empty() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  getDefaultName(...)\n",
      " |      getDefaultName() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  read(...)\n",
      " |      read(fileName) -> None\n",
      " |      .   \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      read(arg1) -> None\n",
      " |      .\n",
      " |  \n",
      " |  write(...)\n",
      " |      write(fileName) -> None\n",
      " |      .   \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      write(fs[, name]) -> None\n",
      " |      .\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Algorithm:\n",
      " |  \n",
      " |  clear(...)\n",
      " |      clear() -> None\n",
      " |      .   @brief Clears the algorithm state\n",
      " |  \n",
      " |  save(...)\n",
      " |      save(filename) -> None\n",
      " |      .   Saves the algorithm to a file.\n",
      " |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SIFT-Merkmale extrahieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "# Schritt 1: Standartisierung der Daten (Features) auf mean=0 und variance=1 - Optimierung der Performance\n",
    "# Schritt 2: PCA mit Variation der Anzahl der Principal Components\n",
    "# Schritt 3: Visualisierung der ersten 2 Principal Components PC1 und PC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Standartisierung\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_hog_01)\n",
    "\n",
    "\n",
    "train_img = scaler.transform(X_train_hog_01)\n",
    "test_img = scaler.transform(X_test_hog_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: PCA mit Variation der Anzahl der Principal Components\n",
    "pca = PCA(n_components=2)\n",
    "# principal_components is an ndarray of shape (n_samples, n_components)\n",
    "principal_components = pca.fit_transform(X_train_hog_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained variance - Varianzanteil jeder der Principal Components  -\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_95 = PCA(.95)\n",
    "pca_95.fit(X_train_hog_01)\n",
    "pca_95.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3: Visualisierung der ersten 2 Principal Components PC1 und PC2#\n",
    "# Anordnen der Daten (PC1, PC2 und ClassIDs) als Spalten einer DataFrame\n",
    "principalDf = pd.DataFrame(data = principal_components, columns = ['principal component 1', 'principal component 2'])\n",
    "principalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels_hog_01_df = pd.DataFrame(y_train_hog_01, columns=['target'])\n",
    "finalDf = pd.concat([principalDf, data_labels_hog_01_df[['target']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten \n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "\n",
    "colors = ['b', 'y', 'r']\n",
    "for considered_class_id, color in zip(CONSIDERED_CLASS_IDs,colors):\n",
    "    indicesToKeep = finalDf['target'] == considered_class_id\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(CONSIDERED_CLASS_IDs)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: PCA for image data in Python\n",
    "# https://www.askpython.com/python/examples/principal-component-analysis-for-image-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation mit SVM-Modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 1\n",
    "Modelltyp - **C_SVC** - kann beim Training nicht linear separierbarer Daten verwendet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/3.4/d1/d73/tutorial_introduction_to_svm.html\n",
    "def create_svm_model():\n",
    "    '''\n",
    "    SVM model\n",
    "    '''\n",
    "    svm_model = cv2.ml.SVM_create()\n",
    "    svm_model.setType(cv2.ml.SVM_C_SVC)\n",
    "    svm_model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "    svm_model.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-6))\n",
    "    \n",
    "    return svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(cv2.ml.SVM_create())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_for_hog_01_features = create_svm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_for_hog_01_features.train(X_train_hog_01, cv2.ml.ROW_SAMPLE, y_train_hog_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_array = svm_for_hog_01_features.predict(X_test_hog_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_hog_01, np.reshape(predicted_y_array[1], y_test_hog_01.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 2\n",
    "https://docs.opencv.org/4.x/d1/d2d/classcv_1_1ml_1_1SVM.html#a533d3d3f950fed3f75be0d8692eeff58\n",
    "SVM-Modell, dessen Parameter waehend des Trainings automatisch optimiert werden\n",
    "\n",
    "(mit Hilfe der Methode trainAuto() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### trainAuto\n",
    "svm_for_hog_01_features2 = cv2.ml.SVM_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_for_hog_01_features2.trainAuto(X_train_hog_01, cv2.ml.ROW_SAMPLE, y_train_hog_01)\n",
    "predicted_y_array_train_auto = svm_for_hog_01_features2.predict(X_test_hog_01)\n",
    "accuracy_score(y_test_hog_01, predicted_y_array_train_auto[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    # times required by the models to train with various sizes of training dataset.\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    # how much time was required to train the models for each training sizes\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = txt_data_hog_01\n",
    "y = data_labels_hog_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "# X, y = load_digits(return_X_y=True)\n",
    "\n",
    "title = \"Learning Curves (Naive Bayes)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = GaussianNB()\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "title = r\"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = SVC(gamma=0.001)\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('BGA2_macos')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f8056f0024b9c33bf88f6b30261f392fae45831253711791418fb2e5b6bf693"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
