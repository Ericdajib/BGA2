{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Uebung 3 Merkmalsextraktion, binaere Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**German Traffic Sign Recognition Benchmark**\n",
    "\n",
    "Detallierte Beschreibung des Datensatzes siehe unter folgendem [Link](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset#Annotationformat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import learning_curve, train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, widgets\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Globale Variablen\n",
    "Um hartcodierte Bezeichner/Namen in den Funktionen zu vermeiden, definiere an dieser Stelle alle Variablen, die global verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prohibitory Class IDs \n",
    "PROHIBITORY_CLASS_IDs = [ 0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 15, 16]\n",
    "\n",
    "# Mandatory Class IDs\n",
    "MANDATORY_CLASS_IDs = [ 33, 34, 35, 36, 37, 38, 39, 40 ]\n",
    "\n",
    "# Danger Class IDs\n",
    "DANGER_CLASS_IDs = [ 11, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 36]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Festlegen, welche Klassen betrachtet werden\n",
    "\n",
    "CONSIDERED_CLASS_IDs = [PROHIBITORY_CLASS_IDs[9], MANDATORY_CLASS_IDs[3]]\n",
    "print(CONSIDERED_CLASS_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Pfade entsprechend eurer Datenstruktu anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Definiere den Pfad zum GTSDB-Datenordner (Detektionsdatensatz)\n",
    "PATH_TO_GTSDB_DATA_FOLDER = './dataset/FullIJCNN2013'\n",
    "# Prüfe, ob der Pfad existiert / korrekt eingegeben wurde\n",
    "assert os.path.exists(PATH_TO_GTSDB_DATA_FOLDER), \"Der angegebene Pfad existriert nicht.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Definiere den Pfad zum GTSRB-Datenordner mit den den ppm-Dateien\n",
    "DATA_PATH_FINAL_TRAINING_IMAGES = './dataset/GTSRB/Final_Training/Images'\n",
    "\n",
    "# Prüfe, ob der Pfad existiert / korrekt eingegeben wurde\n",
    "assert os.path.exists(DATA_PATH_FINAL_TRAINING_IMAGES), \"Der angegebene Pfad existriert nicht.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Definiere den Pfad zum GTSRB-Datenordner mit HOG Features\n",
    "DATA_PATH_HOG_01 = './dataset/GTSRB/Final_Training/HOG/HOG_01'\n",
    "\n",
    "# Prüfe, ob der Pfad existiert / korrekt eingegeben wurde\n",
    "assert os.path.exists(DATA_PATH_HOG_01), \"Der angegebene Pfad existriert nicht.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualisierung der Klassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wiederverwendung des Codes aus UE 1\n",
    "def one_image_per_class(path_to_data_folder):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gibt ein Bild pro Klasse aus (erste Variante)\n",
    "    Argumente: Pfad zum Datenordner\n",
    "    NOTE: 从data folder中提取所有的sub folder，从每一个subfolder中提取第二章图片，并把图片的路径保存到img paths.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Definiere eine leere Liste für Bildpfade\n",
    "    img_paths = []\n",
    "    \n",
    "    # Generiere eine Liste mit den Namen von Unterordnern\n",
    "    subfolders_paths = [os.path.join(path_to_data_folder, subfolder_name) \n",
    "                        for subfolder_name in os.listdir(path_to_data_folder)\n",
    "                        if os.path.isdir(os.path.join(path_to_data_folder, subfolder_name))]\n",
    "    for path in subfolders_paths:\n",
    "        assert os.path.exists(path), \"Der angegebene Pfad existriert nicht.\"\n",
    "        # Gebe z.B. das erste Bild aus\n",
    "        img_path = os.path.join(path, '00001.ppm')\n",
    "        assert os.path.exists(img_path), \"Der angegebene Pfad existriert nicht.\"\n",
    "        img_paths.append(img_path)\n",
    "        \n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_img_tr_sign(idx):\n",
    "    print('ClassID {}'.format(idx))\n",
    "    plt.figure(figsize=(6,6))\n",
    "    img = plt.imread(img_paths_43[idx])\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img_paths_43 = one_image_per_class(PATH_TO_GTSDB_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec0000097bd46dcbc17aefd54c4614f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx', max=42), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(show_img_tr_sign, idx=widgets.IntSlider(min=0,max=len(img_paths_43)-1,step=1, value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Einlesen der Daten und Bilden der train- und test-Datensaetze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_train_test_datasets(CONSIDERED_CLASS_IDs, path_to_data_folder, suffix='txt'):\n",
    "    '''\n",
    "    Liest die Daten aus dem vorgegebenen Datenordner ein und teilt sie in train- und test-Datensaetze auf\n",
    "    从给定的数据文件夹中读取数据，并将其分割成训练和测试数据集。\n",
    "    '''\n",
    "    if suffix != 'txt' and suffix != 'ppm':\n",
    "        print (\"Abbruch der Funktion: Suffix nicht zutreffend. gueltige Suffixes sind txt oder ppm\")\n",
    "        return \n",
    "    \n",
    "    data = []\n",
    "    ppm_data = []\n",
    "    data_labels = []\n",
    "    subfolders_list = os.listdir(path_to_data_folder)\n",
    "    considered_subfolders = [subfolder for subfolder in subfolders_list if int(subfolder) in CONSIDERED_CLASS_IDs]\n",
    "    for subfolder in considered_subfolders:\n",
    "        path_to_considered_datafolder = os.path.join(path_to_data_folder, subfolder)\n",
    "        for filepath in os.listdir(path_to_considered_datafolder):\n",
    "            # Final Training HOG Features of GTSRB-Images\n",
    "            if filepath.endswith(suffix):\n",
    "                full_filepath = os.path.join(path_to_data_folder, subfolder, filepath)\n",
    "                assert os.path.exists(full_filepath), \"Der angegebene Pfad existriert nicht.\"\n",
    "                if suffix == 'txt':\n",
    "                    text_file = open(full_filepath, \"r\")\n",
    "                    txt_lines = text_file.read().split('\\n')\n",
    "                    txt_lines = [float(x) for x in txt_lines]\n",
    "                    data.append(txt_lines)\n",
    "                    data_labels.append(int(subfolder))\n",
    "                else:\n",
    "                    ppm_file = io.imread(full_filepath)\n",
    "                    ppm_file_resized = resize(ppm_file, (40, 40), anti_aliasing=True)\n",
    "                    data.append(ppm_file_resized)\n",
    "                    data_labels.append(int(subfolder))\n",
    "\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    data_labels = np.array(data_labels)\n",
    "    \n",
    "    X_train, X_test, y_tain, y_test = train_test_split(data,data_labels, test_size=0.25, random_state=42)\n",
    "        \n",
    "    \n",
    "    return X_train, X_test, y_tain, y_test, data, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Einlesen der txt-Dateien aus dem GTSRB-Final-Training-HOG1-Datenordner\n",
    "X_train_hog_01, X_test_hog_01, y_train_hog_01, y_test_hog_01, txt_data_hog_01, data_labels_hog_01 = build_train_test_datasets(CONSIDERED_CLASS_IDs, DATA_PATH_HOG_01, suffix='txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Einlesen der ppm-Dateien aus dem GTSRB-Final-Training-Images-Datenordner\n",
    "X_train_img, X_test_img, y_train_img, y_test_img, img_data, img_data_labels = build_train_test_datasets(CONSIDERED_CLASS_IDs, DATA_PATH_FINAL_TRAINING_IMAGES, suffix='ppm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 1568)\n",
      "(2400,)\n"
     ]
    }
   ],
   "source": [
    "print(txt_data_hog_01.shape)\n",
    "print(data_labels_hog_01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of \n",
      "X_train_img: (1800, 40, 40, 3) \n",
      "X_test_img: (600, 40, 40, 3) \n",
      "y_train_img: (1800,) \n",
      "y_test_img: (600,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of \\nX_train_img: {} \\nX_test_img: {} \\ny_train_img: {} \\ny_test_img: {}'.format(X_train_img.shape, X_test_img.shape, y_train_img.shape, y_test_img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_img.shape\n",
    "io.imshow(X_train_img[9])\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Merkmalsextraktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hog = cv2.HOGDescriptor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardeinstellung von cv2.HOGDescriptor():\n",
      "\n",
      "winSize:         (64, 128)\n",
      "blockSize:       (16, 16)\n",
      "blockStride:     (8, 8)\n",
      "cellSize:        (8, 8)\n",
      "nbins:           9\n",
      "winSigma:        -1.0\n",
      "L2HysThreshold:  0.2\n",
      "gammaCorrection: True\n",
      "nlevels:         64\n"
     ]
    }
   ],
   "source": [
    "hog = cv2.HOGDescriptor()\n",
    "print('Standardeinstellung von cv2.HOGDescriptor():\\n')\n",
    "print('winSize:         {}'.format(hog.winSize))\n",
    "print('blockSize:       {}'.format(hog.blockSize))\n",
    "print('blockStride:     {}'.format(hog.blockStride))\n",
    "print('cellSize:        {}'.format(hog.cellSize))\n",
    "print('nbins:           {}'.format(hog.nbins))\n",
    "print('winSigma:        {}'.format(hog.winSigma))\n",
    "print('L2HysThreshold:  {}'.format(hog.L2HysThreshold))\n",
    "print('gammaCorrection: {}'.format(hog.gammaCorrection))\n",
    "print('nlevels:         {}'.format(hog.nlevels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class HOGDescriptor in module cv2:\n",
      "\n",
      "class HOGDescriptor(builtins.object)\n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  checkDetectorSize(...)\n",
      " |      checkDetectorSize() -> retval\n",
      " |      .   @brief Checks if detector size equal to descriptor size.\n",
      " |  \n",
      " |  compute(...)\n",
      " |      compute(img[, winStride[, padding[, locations]]]) -> descriptors\n",
      " |      .   @brief Computes HOG descriptors of given image.\n",
      " |      .   @param img Matrix of the type CV_8U containing an image where HOG features will be calculated.\n",
      " |      .   @param descriptors Matrix of the type CV_32F\n",
      " |      .   @param winStride Window stride. It must be a multiple of block stride.\n",
      " |      .   @param padding Padding\n",
      " |      .   @param locations Vector of Point\n",
      " |  \n",
      " |  computeGradient(...)\n",
      " |      computeGradient(img[, grad[, angleOfs[, paddingTL[, paddingBR]]]]) -> grad, angleOfs\n",
      " |      .   @brief  Computes gradients and quantized gradient orientations.\n",
      " |      .   @param img Matrix contains the image to be computed\n",
      " |      .   @param grad Matrix of type CV_32FC2 contains computed gradients\n",
      " |      .   @param angleOfs Matrix of type CV_8UC2 contains quantized gradient orientations\n",
      " |      .   @param paddingTL Padding from top-left\n",
      " |      .   @param paddingBR Padding from bottom-right\n",
      " |  \n",
      " |  detect(...)\n",
      " |      detect(img[, hitThreshold[, winStride[, padding[, searchLocations]]]]) -> foundLocations, weights\n",
      " |      .   @brief Performs object detection without a multi-scale window.\n",
      " |      .   @param img Matrix of the type CV_8U or CV_8UC3 containing an image where objects are detected.\n",
      " |      .   @param foundLocations Vector of point where each point contains left-top corner point of detected object boundaries.\n",
      " |      .   @param weights Vector that will contain confidence values for each detected object.\n",
      " |      .   @param hitThreshold Threshold for the distance between features and SVM classifying plane.\n",
      " |      .   Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient).\n",
      " |      .   But if the free coefficient is omitted (which is allowed), you can specify it manually here.\n",
      " |      .   @param winStride Window stride. It must be a multiple of block stride.\n",
      " |      .   @param padding Padding\n",
      " |      .   @param searchLocations Vector of Point includes set of requested locations to be evaluated.\n",
      " |  \n",
      " |  detectMultiScale(...)\n",
      " |      detectMultiScale(img[, hitThreshold[, winStride[, padding[, scale[, finalThreshold[, useMeanshiftGrouping]]]]]]) -> foundLocations, foundWeights\n",
      " |      .   @brief Detects objects of different sizes in the input image. The detected objects are returned as a list\n",
      " |      .   of rectangles.\n",
      " |      .   @param img Matrix of the type CV_8U or CV_8UC3 containing an image where objects are detected.\n",
      " |      .   @param foundLocations Vector of rectangles where each rectangle contains the detected object.\n",
      " |      .   @param foundWeights Vector that will contain confidence values for each detected object.\n",
      " |      .   @param hitThreshold Threshold for the distance between features and SVM classifying plane.\n",
      " |      .   Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient).\n",
      " |      .   But if the free coefficient is omitted (which is allowed), you can specify it manually here.\n",
      " |      .   @param winStride Window stride. It must be a multiple of block stride.\n",
      " |      .   @param padding Padding\n",
      " |      .   @param scale Coefficient of the detection window increase.\n",
      " |      .   @param finalThreshold Final threshold\n",
      " |      .   @param useMeanshiftGrouping indicates grouping algorithm\n",
      " |  \n",
      " |  getDaimlerPeopleDetector(...) from builtins.type\n",
      " |      getDaimlerPeopleDetector() -> retval\n",
      " |      .   @brief Returns coefficients of the classifier trained for people detection (for 48x96 windows).\n",
      " |  \n",
      " |  getDefaultPeopleDetector(...) from builtins.type\n",
      " |      getDefaultPeopleDetector() -> retval\n",
      " |      .   @brief Returns coefficients of the classifier trained for people detection (for 64x128 windows).\n",
      " |  \n",
      " |  getDescriptorSize(...)\n",
      " |      getDescriptorSize() -> retval\n",
      " |      .   @brief Returns the number of coefficients required for the classification.\n",
      " |  \n",
      " |  getWinSigma(...)\n",
      " |      getWinSigma() -> retval\n",
      " |      .   @brief Returns winSigma value\n",
      " |  \n",
      " |  load(...)\n",
      " |      load(filename[, objname]) -> retval\n",
      " |      .   @brief loads coefficients for the linear SVM classifier from a file\n",
      " |      .   @param filename Name of the file to read.\n",
      " |      .   @param objname The optional name of the node to read (if empty, the first top-level node will be used).\n",
      " |  \n",
      " |  save(...)\n",
      " |      save(filename[, objname]) -> None\n",
      " |      .   @brief saves coefficients for the linear SVM classifier to a file\n",
      " |      .   @param filename File name\n",
      " |      .   @param objname Object name\n",
      " |  \n",
      " |  setSVMDetector(...)\n",
      " |      setSVMDetector(_svmdetector) -> None\n",
      " |      .   @brief Sets coefficients for the linear SVM classifier.\n",
      " |      .   @param _svmdetector coefficients for the linear SVM classifier.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  L2HysThreshold\n",
      " |      L2HysThreshold\n",
      " |  \n",
      " |  blockSize\n",
      " |      blockSize\n",
      " |  \n",
      " |  blockStride\n",
      " |      blockStride\n",
      " |  \n",
      " |  cellSize\n",
      " |      cellSize\n",
      " |  \n",
      " |  derivAperture\n",
      " |      derivAperture\n",
      " |  \n",
      " |  gammaCorrection\n",
      " |      gammaCorrection\n",
      " |  \n",
      " |  histogramNormType\n",
      " |      histogramNormType\n",
      " |  \n",
      " |  nbins\n",
      " |      nbins\n",
      " |  \n",
      " |  nlevels\n",
      " |      nlevels\n",
      " |  \n",
      " |  signedGradient\n",
      " |      signedGradient\n",
      " |  \n",
      " |  svmDetector\n",
      " |      svmDetector\n",
      " |  \n",
      " |  winSigma\n",
      " |      winSigma\n",
      " |  \n",
      " |  winSize\n",
      " |      winSize\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('/Users/eric/PycharmProjects/BGA2/UE_3/dataset/FullIJCNN2013/00001.ppm')\n",
    "img.shape\n",
    "help(cv2.HOGDescriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_hog_params():\n",
    "    '''\n",
    "    Ueberschreibt Standardeinstellungsparameter von HOGDescriptor()\n",
    "    TODO: Waehle sinnvolle Paameter fuer deinen eigenen HOG-Deskriptor und \n",
    "    extrahiere die HOG-Features für 2 beliebige Klassen\n",
    "    NOTE: 手动填写HOGDescriptor的参数\n",
    "    '''\n",
    "    # Waehle win_size-Parameter (als Tuple anzugeben)\n",
    "    win_size = (800, 1360) # NOTE: size of images are 800*1360\n",
    "    # Waehle block_size-Parameter (als Tuple anzugeben)\n",
    "    block_size = (4, 4) \n",
    "    # Waehle block_stride-Parameter (als Tuple anzugeben)\n",
    "    block_stride = (1, 1) # NOTE: block的步长\n",
    "    # Waehle cell_size-Parameter (als Tuple anzugeben)\n",
    "    cell_size = (4, 4)\n",
    "    # Waehle nbins-Parameter (als Integer anzugeben)\n",
    "    nbins = 7\n",
    "    hog_set = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    return hog_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on xfeatures2d_SIFT object:\n",
      "\n",
      "class xfeatures2d_SIFT(Feature2D)\n",
      " |  Method resolution order:\n",
      " |      xfeatures2d_SIFT\n",
      " |      Feature2D\n",
      " |      Algorithm\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  create(...) from builtins.type\n",
      " |      create([, nfeatures[, nOctaveLayers[, contrastThreshold[, edgeThreshold[, sigma]]]]]) -> retval\n",
      " |      .   @param nfeatures The number of best features to retain. The features are ranked by their scores\n",
      " |      .   (measured in SIFT algorithm as the local contrast)\n",
      " |      .   \n",
      " |      .   @param nOctaveLayers The number of layers in each octave. 3 is the value used in D. Lowe paper. The\n",
      " |      .   number of octaves is computed automatically from the image resolution.\n",
      " |      .   \n",
      " |      .   @param contrastThreshold The contrast threshold used to filter out weak features in semi-uniform\n",
      " |      .   (low-contrast) regions. The larger the threshold, the less features are produced by the detector.\n",
      " |      .   \n",
      " |      .   @param edgeThreshold The threshold used to filter out edge-like features. Note that the its meaning\n",
      " |      .   is different from the contrastThreshold, i.e. the larger the edgeThreshold, the less features are\n",
      " |      .   filtered out (more features are retained).\n",
      " |      .   \n",
      " |      .   @param sigma The sigma of the Gaussian applied to the input image at the octave \\#0. If your image\n",
      " |      .   is captured with a weak camera with soft lenses, you might want to reduce the number.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Feature2D:\n",
      " |  \n",
      " |  compute(...)\n",
      " |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      " |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      " |      .   (second variant).\n",
      " |      .   \n",
      " |      .   @param image Image.\n",
      " |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      " |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      " |      .   with several dominant orientations (for each orientation).\n",
      " |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      " |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      " |      .   descriptor for keypoint j-th keypoint.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      " |      .   @overload\n",
      " |      .   \n",
      " |      .   @param images Image set.\n",
      " |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      " |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      " |      .   with several dominant orientations (for each orientation).\n",
      " |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      " |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      " |      .   descriptor for keypoint j-th keypoint.\n",
      " |  \n",
      " |  defaultNorm(...)\n",
      " |      defaultNorm() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  descriptorSize(...)\n",
      " |      descriptorSize() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  descriptorType(...)\n",
      " |      descriptorType() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  detect(...)\n",
      " |      detect(image[, mask]) -> keypoints\n",
      " |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      " |      .   \n",
      " |      .   @param image Image.\n",
      " |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      " |      .   of keypoints detected in images[i] .\n",
      " |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      " |      .   matrix with non-zero values in the region of interest.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      detect(images[, masks]) -> keypoints\n",
      " |      .   @overload\n",
      " |      .   @param images Image set.\n",
      " |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      " |      .   of keypoints detected in images[i] .\n",
      " |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      " |      .   masks[i] is a mask for images[i].\n",
      " |  \n",
      " |  detectAndCompute(...)\n",
      " |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      " |      .   Detects keypoints and computes the descriptors\n",
      " |  \n",
      " |  empty(...)\n",
      " |      empty() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  getDefaultName(...)\n",
      " |      getDefaultName() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  read(...)\n",
      " |      read(fileName) -> None\n",
      " |      .   \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      read(arg1) -> None\n",
      " |      .\n",
      " |  \n",
      " |  write(...)\n",
      " |      write(fileName) -> None\n",
      " |      .   \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      write(fs[, name]) -> None\n",
      " |      .\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Algorithm:\n",
      " |  \n",
      " |  clear(...)\n",
      " |      clear() -> None\n",
      " |      .   @brief Clears the algorithm state\n",
      " |  \n",
      " |  save(...)\n",
      " |      save(filename) -> None\n",
      " |      .   Saves the algorithm to a file.\n",
      " |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: SIFT-Merkmale extrahieren\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "# Schritt 1: Standartisierung der Daten (Features) auf mean=0 und variance=1 - Optimierung der Performance\n",
    "# Schritt 2: PCA mit Variation der Anzahl der Principal Components\n",
    "# Schritt 3: Visualisierung der ersten 2 Principal Components PC1 und PC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1: Standartisierung\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_hog_01)\n",
    "\n",
    "\n",
    "train_img = scaler.transform(X_train_hog_01)\n",
    "test_img = scaler.transform(X_test_hog_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2: PCA mit Variation der Anzahl der Principal Components\n",
    "pca = PCA(n_components=2)\n",
    "# principal_components is an ndarray of shape (n_samples, n_components)\n",
    "principal_components = pca.fit_transform(X_train_hog_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# explained variance - Varianzanteil jeder der Principal Components  -\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pca_95 = PCA(.95)\n",
    "pca_95.fit(X_train_hog_01)\n",
    "pca_95.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#3: Visualisierung der ersten 2 Principal Components PC1 und PC2#\n",
    "# Anordnen der Daten (PC1, PC2 und ClassIDs) als Spalten einer DataFrame\n",
    "principalDf = pd.DataFrame(data = principal_components, columns = ['principal component 1', 'principal component 2'])\n",
    "principalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_labels_hog_01_df = pd.DataFrame(y_train_hog_01, columns=['target'])\n",
    "finalDf = pd.concat([principalDf, data_labels_hog_01_df[['target']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plotten \n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "\n",
    "colors = ['b', 'y', 'r']\n",
    "for considered_class_id, color in zip(CONSIDERED_CLASS_IDs,colors):\n",
    "    indicesToKeep = finalDf['target'] == considered_class_id\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(CONSIDERED_CLASS_IDs)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Beispiel: PCA for image data in Python\n",
    "# https://www.askpython.com/python/examples/principal-component-analysis-for-image-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Klassifikation mit SVM-Modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Modell 1\n",
    "Modelltyp - **C_SVC** - kann beim Training nicht linear separierbarer Daten verwendet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/3.4/d1/d73/tutorial_introduction_to_svm.html\n",
    "def create_svm_model():\n",
    "    '''\n",
    "    SVM model\n",
    "    '''\n",
    "    svm_model = cv2.ml.SVM_create()\n",
    "    svm_model.setType(cv2.ml.SVM_C_SVC)\n",
    "    svm_model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "    svm_model.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-6))\n",
    "    \n",
    "    return svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "help(cv2.ml.SVM_create())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svm_for_hog_01_features = create_svm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svm_for_hog_01_features.train(X_train_hog_01, cv2.ml.ROW_SAMPLE, y_train_hog_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_y_array = svm_for_hog_01_features.predict(X_test_hog_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test_hog_01, np.reshape(predicted_y_array[1], y_test_hog_01.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Modell 2\n",
    "https://docs.opencv.org/4.x/d1/d2d/classcv_1_1ml_1_1SVM.html#a533d3d3f950fed3f75be0d8692eeff58\n",
    "SVM-Modell, dessen Parameter waehend des Trainings automatisch optimiert werden\n",
    "\n",
    "(mit Hilfe der Methode trainAuto() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### trainAuto\n",
    "svm_for_hog_01_features2 = cv2.ml.SVM_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svm_for_hog_01_features2.trainAuto(X_train_hog_01, cv2.ml.ROW_SAMPLE, y_train_hog_01)\n",
    "predicted_y_array_train_auto = svm_for_hog_01_features2.predict(X_test_hog_01)\n",
    "accuracy_score(y_test_hog_01, predicted_y_array_train_auto[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    # times required by the models to train with various sizes of training dataset.\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    # how much time was required to train the models for each training sizes\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X = txt_data_hog_01\n",
    "y = data_labels_hog_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "# X, y = load_digits(return_X_y=True)\n",
    "\n",
    "title = \"Learning Curves (Naive Bayes)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = GaussianNB()\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "title = r\"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = SVC(gamma=0.001)\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('BGA2_macos')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f8056f0024b9c33bf88f6b30261f392fae45831253711791418fb2e5b6bf693"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}